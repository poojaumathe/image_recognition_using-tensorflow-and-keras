{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Using Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooja Umathe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Recognition (Classification):\n",
    "Image recognition refers to the task of inputting an image into a neural network and having it output some kind of label for that image. The label that the network outputs will correspond to a pre-defined class. There can be multiple classes that the image can be labeled as, or just one. If there is a single class, the term \"recognition\" is often applied, whereas a multi-class recognition task is often called \"classification\".\n",
    "\n",
    "A subset of image classification is object detection, where specific instances of objects are identified as belonging to a certain class like animals, cars, or people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be using the famous CIFAR-10 dataset. \n",
    "\n",
    "CIFAR-10 is a large image dataset containing over 60,000 images representing 10 different classes of objects like cats, planes, and cars.\n",
    "\n",
    "The images are full-color RGB, but they are fairly small, only 32 x 32. One great thing about the CIFAR-10 dataset is that it comes prepackaged with Keras, so it is very easy to load up the dataset and the images need very little preprocessing.\n",
    "\n",
    "The first thing we should do is import the necessary libraries;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required Libraries and packages\n",
    "\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data from Keras\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 21\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 25\n",
    "optimizer = 'Adam'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,264,458\n",
      "Trainable params: 2,263,114\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing model summary\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 1421s 28ms/step - loss: 1.5219 - accuracy: 0.4605 - val_loss: 1.1838 - val_accuracy: 0.5720\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 850s 17ms/step - loss: 1.0215 - accuracy: 0.6389 - val_loss: 0.8786 - val_accuracy: 0.6942\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 610s 12ms/step - loss: 0.8569 - accuracy: 0.6987 - val_loss: 0.8209 - val_accuracy: 0.7182\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 651s 13ms/step - loss: 0.7627 - accuracy: 0.7316 - val_loss: 0.6941 - val_accuracy: 0.7578\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 767s 15ms/step - loss: 0.7041 - accuracy: 0.7537 - val_loss: 0.7781 - val_accuracy: 0.7244\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 736s 15ms/step - loss: 0.6582 - accuracy: 0.7693 - val_loss: 0.6414 - val_accuracy: 0.7733\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 636s 13ms/step - loss: 0.6289 - accuracy: 0.7816 - val_loss: 0.6463 - val_accuracy: 0.7782\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 693s 14ms/step - loss: 0.6139 - accuracy: 0.7842 - val_loss: 0.6387 - val_accuracy: 0.7825\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 756s 15ms/step - loss: 0.5761 - accuracy: 0.8002 - val_loss: 0.6315 - val_accuracy: 0.7829\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 768s 15ms/step - loss: 0.5550 - accuracy: 0.8078 - val_loss: 0.6063 - val_accuracy: 0.7920\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 713s 14ms/step - loss: 0.5414 - accuracy: 0.8104 - val_loss: 0.5665 - val_accuracy: 0.8021\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 659s 13ms/step - loss: 0.5254 - accuracy: 0.8161 - val_loss: 0.5845 - val_accuracy: 0.7970\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 661s 13ms/step - loss: 0.5119 - accuracy: 0.8231 - val_loss: 0.5328 - val_accuracy: 0.8171\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 652s 13ms/step - loss: 0.4984 - accuracy: 0.8249 - val_loss: 0.5485 - val_accuracy: 0.8130\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 639s 13ms/step - loss: 0.4888 - accuracy: 0.8298 - val_loss: 0.6403 - val_accuracy: 0.7790\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 646s 13ms/step - loss: 0.4763 - accuracy: 0.8346 - val_loss: 0.6002 - val_accuracy: 0.7966\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 679s 14ms/step - loss: 0.4682 - accuracy: 0.8372 - val_loss: 0.5677 - val_accuracy: 0.8086\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 704s 14ms/step - loss: 0.4640 - accuracy: 0.8367 - val_loss: 0.5128 - val_accuracy: 0.8283\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 731s 15ms/step - loss: 0.4469 - accuracy: 0.8439 - val_loss: 0.5528 - val_accuracy: 0.8087\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 734s 15ms/step - loss: 0.4459 - accuracy: 0.8443 - val_loss: 0.5191 - val_accuracy: 0.8232\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 734s 15ms/step - loss: 0.4416 - accuracy: 0.8465 - val_loss: 0.5322 - val_accuracy: 0.8171\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 737s 15ms/step - loss: 0.4401 - accuracy: 0.8451 - val_loss: 0.5273 - val_accuracy: 0.8185\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 740s 15ms/step - loss: 0.4322 - accuracy: 0.8475 - val_loss: 0.5238 - val_accuracy: 0.8205\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 744s 15ms/step - loss: 0.4228 - accuracy: 0.8518 - val_loss: 0.5554 - val_accuracy: 0.8111\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 739s 15ms/step - loss: 0.4191 - accuracy: 0.8540 - val_loss: 0.5218 - val_accuracy: 0.8274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ff0c515a48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.74%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
